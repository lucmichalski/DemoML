{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StepbyStep搭建分词工具\n",
    "\n",
    "### 方法 1  穷举法搭建中文分词\n",
    "\n",
    "给定词典=[自然，语言，处理，是，机器，学习，机器学习，的，一个，应用，场景，自然语言处理， 自然语言，应用场景， 语言处理]\n",
    "另外给定unigram概率：p(自然语言处理)=0.25, p(机器学习)=0.15, p(应用场景)=0.05, p(机器学习)=0.1, p(的)=0.2, p(一个)=0.1, p(是)=0.15\n",
    "\n",
    "#### Step 1: 对于给定句子：”自然语言处理是机器学习的一个应用场景“, 找出所有可能的分词方式\n",
    "- [自然，语言，处理，是，机器，学习，的，一个，应用，场景]\n",
    "- [自然语言处理，是，机器学习，的，一个，应用场景]\n",
    "- [自然语言，处理，是，机器，学习，的，一个，应用，场景]\n",
    "- [自然，语言处理，是，机器，学习，的，一个，应用场景]\n",
    ".......\n",
    "\n",
    "\n",
    "#### Step 2: 计算出每一个分词之后句子的概率\n",
    "- p(自然，语言，处理，是，机器，学习，的，一个，应用，场景)= -log p(自然)-log p(语言)-log p(处理)-log p(是)-log p(机器)-log p(学习)-log p(的)-log p(一个)-log p(应用)-log p(场景)\n",
    "- p(自然语言处理，是，机器学习，的，一个，应用场景)=-log p(自然语言处理)-log p(是)-log p(机器学习)-log p(的)-log p(一个)-log p(应用场景)\n",
    "- p(自然语言，处理，是，机器，学习，的，一个，应用，场景)=-log p(自然语言)-log p(处理)-log p(是)-log p(机器)-log p(学习)-log p(的)-log p(一个)-log p(应用)-log p(场景)\n",
    "- p(自然，语言处理，是，机器，学习，的，一个，应用场景)=-log p(自然)-log p(语言处理)-log p(是)-log p(机器)-log p(学习)-log p(的)-log p(一个)-log p(应用场景)\n",
    ".....\n",
    "\n",
    "#### Step 3: 返回第二步中概率最大的分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "word_prob = {\"上海\":0.03,\"的\":0.08,\"天\":0.005,\"气\":0.005,\"天气\":0.06,\"真\":0.04,\"好\":0.05,\"真好\":0.04,\"啊\":0.03, \n",
    "             \"今\":0.01,\"今天\":0.07,\"电视\":0.06,\"电视剧\":0.06,\"有\":0.05,\"很\":0.04,\"趣\":0.06,\"有趣\":0.035,\"电\":0.01,\n",
    "             \"视\":0.005,\"经常\":0.08,\"意见\":0.08,\"意\":0.01,\"见\":0.005,\"有意见\":0.02,\"分歧\":0.04,\"分\":0.02, \"歧\":0.005}\n",
    "dic_words = set(word_prob.keys())\n",
    "# 如果有其他的字典可以存放到dic_words里\n",
    "print (sum(word_prob.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_helper(s, wordDict, memo):\n",
    "    if s in memo: return memo[s]\n",
    "    if not s: return []\n",
    "\n",
    "    res = []\n",
    "    for i in range(len(s)):\n",
    "        if s[:i+1] not in wordDict:\n",
    "            continue\n",
    "        if i == len(s)-1:\n",
    "            res.append([s[:i+1]])\n",
    "        else:\n",
    "            resultOfTheRest = seg_helper(s[i+1:], wordDict, memo)\n",
    "            for item in resultOfTheRest:\n",
    "                item = [s[:i+1]] + item\n",
    "                res.append(item)\n",
    "    memo[s] = res\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10\n",
    "\n",
    "def seg_prob(segment, word_prob):\n",
    "    best_score = float(\"inf\")\n",
    "    best_segment = []\n",
    "    for segment in segments:\n",
    "        prob = 0\n",
    "        for word in segment:\n",
    "            if word in word_prob.keys():\n",
    "                prob += -log10(word_prob[word])\n",
    "            else:\n",
    "                prob += -log10(0.00001)\n",
    "#         prob = prob/len(segment)\n",
    "        if best_score >= prob:\n",
    "            best_score = prob\n",
    "            best_segment = segment\n",
    "    return best_score, best_segment\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveSegmentor(input_str):\n",
    "    \"\"\"\n",
    "    1. 对于输入字符串做分词，并返回所有可行的分词之后的结果。\n",
    "    2. 针对于每一个返回结果，计算句子的概率\n",
    "    3. 返回概率最高的分词\n",
    "    \n",
    "    input_str: 输入字符串   输入格式：“上海今天的天气真好”\n",
    "    best_segment: 最好的分词结果  输出格式：[\"上海\"，\"今天\"，\"的\"，\"天气\",\"真好\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # 第一步： 计算所有可能的分词结果，要保证每个分完的词存在于词典里，这个结果有可能会非常多。 \n",
    "    segments = []  # 存储所有分词的结果。如果次字符串不可能被完全切分，则返回空列表(list)\n",
    "                   # 格式为：segments = [['上海', '的', '天', '气', '真', '好', '啊'], ['上海', '的', '天', '气', '真好', '啊'],...]\n",
    "    segments = seg_helper(input_str, dic_words, {})\n",
    "    # 第二步：循环所有的分词结果，并计算出概率最高的分词结果，并返回\n",
    "    best_segment = []\n",
    "    best_score = float(\"inf\")\n",
    "    for seg in segments:\n",
    "        prob = 0\n",
    "        for word in seg:\n",
    "            if word in word_prob.keys():\n",
    "                prob += -log10(word_prob[word])\n",
    "            else:\n",
    "                prob += -log10(0.00001)\n",
    "#         prob = prob/len(seg)\n",
    "        if best_score >= prob:\n",
    "            best_score = prob\n",
    "            best_segment = seg\n",
    "    \n",
    "    return best_segment      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海', '的', '天气', '真好', '啊']\n",
      "['今天', '的', '电视剧', '很', '有趣']\n",
      "['经常', '有意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "print(NaiveSegmentor(\"上海的天气真好啊\"))\n",
    "print(NaiveSegmentor(\"今天的电视剧很有趣\"))\n",
    "print(NaiveSegmentor(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法 2  用维特比算法来优化上述流程\n",
    "#### 1.代码展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海', '的', '天气', '真好', '啊']\n",
      "['今天', '的', '电视剧', '很', '有趣']\n",
      "['经常', '有意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "def graph(input_str):\n",
    "    graph = []\n",
    "    # 定义为以这个字为结尾的所有单词\n",
    "    for i in range(1,len(input_str)+1,1):\n",
    "        path_i = {i-1:-log10(0.00001)}\n",
    "        for j in range(i-1, -1, -1):\n",
    "            word = input_str[j:i]\n",
    "            if word in dic_words:\n",
    "                if word in word_prob.keys():\n",
    "                    path_i[j] = -log10(word_prob[word])\n",
    "                else:\n",
    "                    path_i[j] = -log10(0.00001)\n",
    "        graph.append(path_i)\n",
    "    return graph\n",
    "\n",
    "def viterbi_path_direct(input_str, graph):\n",
    "    memo_path = {}\n",
    "    memo_score = {}\n",
    "    for i in range(len(input_str)):\n",
    "        best_score = float('inf')\n",
    "        best_path = []\n",
    "        best_seg = []\n",
    "        for start_word in graph[i].keys():\n",
    "            #calculate score\n",
    "            if start_word == 0:\n",
    "                score = graph[i][start_word]\n",
    "#                 path = [start_word] + [i]\n",
    "                path = [input_str[:i+1]]\n",
    "                \n",
    "            elif start_word == i:\n",
    "                score = memo_score[start_word-1] + graph[i][i]\n",
    "#                 path = memo_path[start_word-1] + [i]\n",
    "                path = memo_path[start_word-1] +  [input_str[start_word:i+1]]\n",
    "                \n",
    "            elif start_word != 0:\n",
    "                score = memo_score[start_word-1] + graph[i][start_word]\n",
    "#                 path = memo_path[start_word-1] + [i]\n",
    "                path = memo_path[start_word-1] + [input_str[start_word:i+1]]\n",
    "                \n",
    "            \n",
    "            # compare and save\n",
    "            if score <= best_score:\n",
    "                best_score = score\n",
    "                best_path= path\n",
    "                \n",
    "        memo_path[i] = best_path\n",
    "        memo_score[i] = best_score\n",
    "    \n",
    "    return memo_path[len(input_str)-1]\n",
    "\n",
    "def ViterbiSegmentor(input_str):\n",
    "    graph_input = graph(input_str)\n",
    "    return viterbi_path_direct(input_str, graph_input)\n",
    "# 测试\n",
    "print(ViterbiSegmentor(\"上海的天气真好啊\"))\n",
    "print(ViterbiSegmentor(\"今天的电视剧很有趣\"))\n",
    "print(ViterbiSegmentor(\"经常有意见分歧\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.分步骤理解以上过程\n",
    "    1. 基于输入字符串，词典，以及给定的unigram概率来创建DAG(有向图）。\n",
    "    2. 编写维特比算法来寻找最优的PATH\n",
    "    3. 返回分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(input_str, graph):\n",
    "    memo_path = {}\n",
    "    memo_score = {}\n",
    "    for i in range(len(input_str)):\n",
    "        best_score = float('inf')\n",
    "        best_path = []\n",
    "        best_seg = []\n",
    "        for start_word in graph[i].keys():\n",
    "            #calculate score\n",
    "            if start_word == 0:\n",
    "                score = graph[i][start_word]\n",
    "                path = [start_word] + [i]\n",
    "#                 path = [input_str[:i+1]]\n",
    "                \n",
    "            elif start_word == i:\n",
    "                score = memo_score[start_word-1] + graph[i][i]\n",
    "                path = memo_path[start_word-1] + [i]\n",
    "#                 path = memo_path[start_word-1] +  [input_str[start_word:i+1]]\n",
    "                \n",
    "            elif start_word != 0:\n",
    "                score = memo_score[start_word-1] + graph[i][start_word]\n",
    "                path = memo_path[start_word-1] + [i]\n",
    "#                 path = memo_path[start_word-1] + [input_str[start_word:i+1]]\n",
    "                \n",
    "            \n",
    "            # compare and save\n",
    "            if score <= best_score:\n",
    "                best_score = score\n",
    "                best_path= path\n",
    "                \n",
    "        memo_path[i] = best_path\n",
    "        memo_score[i] = best_score\n",
    "    \n",
    "    return memo_path[len(input_str)-1]\n",
    "\n",
    "\n",
    "def ViterbiSegmentor(input_str):\n",
    "    \"\"\"\n",
    "    1. 基于输入字符串，词典，以及给定的unigram概率来创建DAG(有向图）。\n",
    "    2. 编写维特比算法来寻找最优的PATH\n",
    "    3. 返回分词结果\n",
    "    \n",
    "    input_str: 输入字符串   输入格式：“上海今天的天气真好”\n",
    "    best_segment: 最好的分词结果  输出格式：[\"上海\"，\"今天\"，\"的\"，\"天气\",\"真好\"]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 第一步：\n",
    "    # 根据词典，词典概率，和输入的句子，以及给定的unigram概率来创建带权重的有向图\n",
    "    # 有向图的每一条边对应为一个单词的概率，\n",
    "    # 这些概率在 word_prob，如果不在word_prob里的单词但在\n",
    "    # 词典里存在的，统一用概率值0.00001。\n",
    "    # 不一定有只有一种方式来存储这种结构。 \n",
    "    graph = []\n",
    "    # 定义为以这个字为结尾的所有单词\n",
    "    for i in range(1,len(input_str)+1,1):\n",
    "        path_i = {i-1:-log10(0.00001)}\n",
    "        for j in range(i-1, -1, -1):\n",
    "            word = input_str[j:i]\n",
    "            if word in dic_words:\n",
    "                if word in word_prob.keys():\n",
    "                    path_i[j] = -log10(word_prob[word])\n",
    "                else:\n",
    "                    path_i[j] = -log10(0.00001)\n",
    "        graph.append(path_i)\n",
    "           \n",
    "    \n",
    "    \n",
    "    # 第二步：\n",
    "    # 利用维特比算法来找出最好的路径， 使得P(sentence)最大 。\n",
    "    # 使用negative log sum:  -log(w1)-log(w2)-...\n",
    "    # 所以返回-log P(sentence)最小的PATH\n",
    "\n",
    "    # 太长了于是写了函数，注意这里的维特比函数和上面展示的有所区别\n",
    "    \n",
    "    path = viterbi(input_str, graph) \n",
    "    \n",
    "    # 第三步： 根据最好路径, 返回最好的分词\n",
    "    start = 0\n",
    "    best_segment = []\n",
    "    for idx in path[1:]:\n",
    "        best_segment.append(input_str[start:idx+1])\n",
    "        start = idx+1\n",
    "    \n",
    "    return best_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海', '的', '天气', '真好', '啊']\n",
      "['今天', '的', '电视剧', '很', '有趣']\n",
      "['经常', '有意见', '分歧']\n",
      "['我', '们', '经常', '有意见', '分歧']\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "print(ViterbiSegmentor(\"上海的天气真好啊\"))\n",
    "print(ViterbiSegmentor(\"今天的电视剧很有趣\"))\n",
    "print(ViterbiSegmentor(\"经常有意见分歧\"))\n",
    "print(ViterbiSegmentor(\"我们经常有意见分歧\")) # 因为 我们 没有在字典里，因此直接分开了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "# 需要其他字的话可以利用dic_words变量存储字典\n",
    "# 就是一个小demo哈哈\n",
    "# 骚操作来了，一般来说……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 绝招放在最后，其实最简单的办法就是"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 然后"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/2x/836bc66165lc4dm4r05cmh7c0000gn/T/jieba.cache\n",
      "Loading model cost 0.780 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "故天 之道 利而 不害 圣人 之道 为 而 弗争\n",
      "道 可道 也 非恒道 也 名 可名 也 非恒名 也\n",
      "有名 万物 之始 也 无名 万物 之母 也\n",
      "经常 有 意见分歧\n"
     ]
    }
   ],
   "source": [
    "text = \"故天之道利而不害圣人之道为而弗争\"\n",
    "text2 = \"道可道也非恒道也名可名也非恒名也\"\n",
    "text3 = \"有名万物之始也无名万物之母也\"\n",
    "# jieba.cut直接得到generator形式的分词结果\n",
    "seg = jieba.cut(text)  \n",
    "print(' '.join(seg)) \n",
    "print(' '.join(jieba.cut(text2)))\n",
    "print(' '.join(jieba.cut(text3)))\n",
    "# ……似乎对古文的分词不太友好\n",
    "text4 = \"经常有意见分歧\"\n",
    "print(' '.join(jieba.cut(text4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
